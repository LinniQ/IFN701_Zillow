---
title: 'IFN701: Zillow''s Home Value Prediction (Zestimate) --- Round 1 Logerror Prediction'
author: "Linni, QIN n9632981"
output:
  html_document: default
  pdf_document: default
---

## Introduction

  This R markdown file is going to find out the logerror of Zestimate in Oct. Nov. Dec. of 2017, which is associated to 3millions of properties in three counties in California, USA (LA, OR, VA). The prediction model will be trained and check the accuracy based on using the similar datasets of 2016. Logerror is the difference between the Zestimate's preicted market value and the actual sales price of the particular property.(Note: Detail introcution can be referred to Project Proposal)

# Official data from Kaggle:
  train_2016_v2.csv and train_2017 contatin the logerror of properties sold within three specific counties through 2016 and 2017 respectively.
  properties_2016.csv and properties_2017.csv include the total 3millions of properties within three specific counties with common 57 attributes such as room numbers, square footage and locations. The parcelid of these two years are the same but the information of their attributes are different with certain level.

# Outcomes:

1. data analysis report: find out the valuable data from the samples
eg.
    the pattern of the sales 
    the pattern of the error distribution (flat and vertical versions, overestimation (56%) > underestimation (44%))
    
    the parttern of missing data
    --- 28 features contain more than 70% of data for parcelids
    --- 29 features contain less than 70% of data for parcelides (not used)
    
    the factors to influcence the home value:
    --- transaction counts: cor (-0.7130957)
    --- individual features appear no correlationships with logerror, but their respective frequencies dedicate kind of negative and positive relations.
    
2. Prediction model
eg.
    Multiple regression to predict the logerror
      --- prediction based on the datasize
      --- prediction based on the important features
    MSE to measure the accuracy of the predictions


# Call the useful packages

```{r}
library(lubridate)
library(ggplot2)
library(plyr)
#install.packages("dplyr")
library(dplyr)

#install.packages("corrplot")
library(corrplot)

#install.packages("Metrics")
library(Metrics)

```


# Import the available data

```{r}

train16 <- read.csv("./train_2016_v2.csv", header = TRUE)
train17 <- read.csv("./train_2017.csv", header = TRUE) 

prop16 <- read.csv("./properties_2016.csv", header = TRUE)
prop17 <- read.csv("./properties_2017.csv", header = TRUE)
```

```{r}
# check any difference between the property features of 2017 and 2016
all(colnames(prop16)==colnames(prop17))
```

```{r}
# the total number of the parcelid looks the same but check any difference between the parcelid of 2017 and 2016
all(unique(prop16$parcelid)== unique(prop17$parcelid))
```

There are the same physical features for the properties of both 2016 and 2017, but there exist some differences among the parcelids.

## Part 1: Data Analysis

# 1.1 Data preparation and the overview of statics value of 2016 and 2017's logerror.

  First of all, let's explore the train_2016 and train_2017's Error rate, Transaction pattern and Logerror Distribution.
  
# A.Prepare the data of training data of 2016 and 2017 equally

```{r}
# convert the date into month for further visulation analysis
#train16$month <- months(as.Date(train16$transactiondate, format = "%d/%m/%y"))
train16$month <- month(train16$transactiondate)
train16$transactiondate <- gsub("[/]", "" , train16$transactiondate, perl=TRUE)
train16$transactiondate <- as.numeric(train16$transactiondate)
is.numeric(train16$transactiondate) # check if the numeric transfermation is successful.
```

  The current train16 contains logerror for sold parcelids througout 2016 as stated by Kaggle. Then, the training data of 2017 is available from January to September. We need to predict the logerror of last quarter of 2017. In the meantime, the prediction model needs to be built based on the training data of 2016 from January to September, then its accuracy can be check by using the available logerror in the last quarter of 2016. Beforehand, let's keep the month range of both training datasets equally for further analysis.

```{r}
train16_beforeOct <- subset(train16, month < 10)
train16_afterOct <- subset(train16, month >=10)
```
  Before October of 2016, there were 81733 parcelids which were sold. In the last quarter of 2016, 8542 parcelids were sold.

```{r}
train17$month <- month(train17$transactiondate)
train17$transactiondate <- gsub("[-]", "" , train17$transactiondate, perl=TRUE)
train17$transactiondate <- as.numeric(train17$transactiondate)
is.numeric(train17$transactiondate)
```

  Check the statistic logerror data of both 2016 and 2017.
```{r}
summarise(train16_beforeOct, Median=median(train16_beforeOct$logerror), Mean= mean(train16_beforeOct$logerror), Max=max(train16_beforeOct$logerror), Min=min(train16_beforeOct$logerror), Std=sd(train16_beforeOct$logerror)) 
```

```{r}
summarise(train17, Median=median(train17$logerror), Mean= mean(train17$logerror), Max=max(train17$logerror), Min=min(train17$logerror), Std=sd(train17$logerror)) 

```

  Studying from the above statics values, the accuracy of prediction of 2017 appears a bit worse than 2016 because the median, mean and standard deviation of 2017 perform slightly higher than that of 2016. Meanwhile, the outliners of 2017's logerror goes a bit far away of its median value while comparing that with 2016. More analysis about the logerror will be done in section 1.3.2 to confirm if the logerror performance of 2017 does really worse than 2016.


# 1.2 Pattern of Transaction Frequency of Zillow.

# 1.2.1 The transaction frequency of whole 2016.

```{r,fig.width=7, fig.height=5}

transactionCount16A <- ddply(train16, .(month), "nrow") 
names(transactionCount16A)[2] <- c("transactioncount")

ggplot(transactionCount16A, aes(x= month, y=transactioncount)) + geom_point(color="brown", size=5) + geom_line(color="brown", size=1.5) + xlab("Months") + ylab("Transaction Counts of Properties on Zillow (2016)")+ scale_x_continuous(limits = c(1, 12), breaks = seq(1, 12, 1)) + scale_y_continuous(limits = c(0, 11500), breaks = seq(0, 11500, 2000)) + geom_hline(yintercept = mean(transactionCount16A$transactioncount),linetype = "dashed", size = 1.5, color = "purple")  + theme_bw()
```

The purple dashed line is the mean of the transaction time of Zillow in 2016. It can be learned from the diagram that it was a cold market from October to December. Their volume is far lower than the mean of transaction counts. Starting from March to September, there was a hot market for the property transaction. 


# 1.2.2 Transaction frequency before the October of 2016 and 2017
```{r,fig.width=7, fig.height=5}
transactionCount16B <- ddply(train16_beforeOct, .(month), "nrow") 
names(transactionCount16B)[2] <- c("transactioncount")
transactionCount17B <- ddply(train17, .(month), "nrow") 
names(transactionCount17B)[2] <- c("transactioncount")
```

  Let's plot two years transaction frequency in one image as below. 

```{r,fig.width=7, fig.height=5}
months <- 1:9
t16 <- transactionCount16B$transactioncount
t17 <- transactionCount17B$transactioncount

plot(months, t16, pch=0, type="b", col="red", ylim=c(0, 11500))
par(new=TRUE)
plot(months,t17, pch=1, type="b", col="blue", ylim=c(0, 11500))
```
  The red line is the frequency of 2016, then the blue line is the frequency of 2017. It significantly shows that the transaction in September of 2017 reduces greatly than the transaction in the same period of 2016. Regarding the other eight months, the transaction frequency developed similiarly.

# 1.3 Logerror Distribution pattern of Zillow in 2016 and 2017

# 1.3.1 Logerror distribution of 2016 (before October)

  The mean of the logerror we got from the last section is near 0.011. Let's narrow down the plot range of the logerror from 1 to -1 to explore its dirstribution.

```{r,fig.width=10, fig.height=7} 
ggplot(train16_beforeOct) + geom_jitter(aes(x=month, y=logerror), stat = "identity", color = "brown") + xlab ("Months (2016)") + ylab("Logerror Distribution") +scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, 1))+ scale_y_continuous(limits = c(-1, 1), breaks = seq(-1, 1, 0.025)) + geom_hline(yintercept = 0.011 ,linetype = "dashed", size = 1, color = "black")+ theme_bw()
```

  Check the amount of overestimation and understimation of 2016

```{r,fig.width=10, fig.height=7}
nrow(train16_beforeOct[train16_beforeOct$logerror >= 0,]) #45390, overestimation is more than underestimation
nrow(train16_beforeOct[train16_beforeOct$logerror < 0,]) #36343
```

# 1.3.2 Logerror distribution of 2017 (before October)
  The mean of the logerror we got from the last section is near 0.017. Let's narrow down the plot range of the logerror from 1 to -1 to explore its dirstribution.
```{r,fig.width=10, fig.height=7} 

ggplot(train17) + geom_jitter(aes(x=month, y=logerror), stat = "identity", color = "brown") + xlab ("Months (2017)") + ylab("Logerror Distribution") +scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, 1))+ scale_y_continuous(limits = c(-1, 1), breaks = seq(-1, 1, 0.025)) + geom_hline(yintercept = 0.017 ,linetype = "dashed", size = 1, color = "black")+ theme_bw()


```

  Check the amount of overestimation and understimation of 2017
  As similar as 2016, the Zestimate made the overestimation than uderestimation in 2017.

```{r,fig.width=10, fig.height=7}
nrow(train17[train17$logerror >= 0,]) #43897, overestimation is more than underestimation
nrow(train17[train17$logerror < 0,]) #33716
```

  In conclusion, except the logerror show a high tense of distribution around 0, we cannot learn too much from the distribution of these two years. They looks nearly the same. Let's try to find out if there any difference of their logerror monthly mean.

# 1.3.3 Relationship between Monthly Logerror Mean and the Monthly Transaction Counts (2016 + 2017)

```{r,fig.width=7, fig.height=5}

errorCount16B <- ddply(train16_beforeOct, c("month"), summarise, mean = mean(logerror))
errorCount17B <- ddply(train17, c("month"), summarise, mean = mean(logerror))

months <- 1:9
e16 <- errorCount16B$mean
e17 <- errorCount17B$mean

plot(months, e16, pch=0, type="b", col="red", yaxt="n",ylim=c(0, 0.04))
par(new=TRUE)
plot(months,e17, pch=1, type="b", col="blue", yaxt="n",ylim=c(0, 0.04))
axis(side=2)
axis(side=4)

```
  As indicated as the above graph, we can conclude that the performance of 2016 logerror prediction achieved better work than 2017 does.
  Furthermore, comparing the monthly logerror mean graph and the image of monthly transaction frequency, it is noted that the distribution of those two datasets appears some negative relationship. When the transaction goes high, the logeeror goes low. It means more transaction causes the logerror more accuracy.
  Let's use the combined plotting image to see if there is a clear trend as what we assumed.
  
# Relathionship between 2016 monthly transaction volume and monthly logerror mean
  
```{r,fig.width=7, fig.height=5}

months <- 1:9
e16 <- errorCount16B$mean
t16 <- transactionCount16B$transactioncount

plot(months, e16, pch=0, type="b", col="red",yaxt="n", ylim=c(0, 0.04))
par(new=TRUE)
plot(months,t16, pch=1, type="b", col="blue",yaxt="n", ylim=c(0, 11500))
axis(side=2, at=c(0, 0.04))
axis(side=4, at=c(0, 11500))

```
# Relathionship between 2017 monthly transaction volume and monthly logerror mean
```{r,fig.width=7, fig.height=5}

months <- 1:9
e17 <- errorCount17B$mean
t17 <- transactionCount17B$transactioncount

plot(months, e17, pch=0, type="b", col="red",yaxt="n", ylim=c(0, 0.04))
par(new=TRUE)
plot(months,t17, pch=1, type="b", col="blue",yaxt="n", ylim=c(0, 11500))
axis(side=2, at=c(0, 0.04))
axis(side=4, at=c(0, 11500))

```
  
  As indicated as the above two graphs, the blue lines denote the monthly transaction frequencies. The red lines denote the monthly logerror means. The high logerrors happened when the transaction frequency stayed low. A stable flutuation of the low error happened when the transaction frequency stayed with high volume. These two variables run in the opposite directions as shown. Let's check their correlation rate by using cor().

```{r,fig.width=10, fig.height=7}
cor(errorCount16B$mean, transactionCount16B$transactioncount)
cor(errorCount17B$mean, transactionCount17B$transactioncount)
```

  In staticstics, the correlation is represented within the range of -1, 0 and 1. 0 indicates no correlation and 1 denotes a positive correlation.

  The negative correlation as found above between the logerror and the transaction numbers denotes while transaction number increases the logeeror decreases. (http://www.investopedia.com/terms/n/negative-correlation.asp)

  Question: Can we use the transanction frequency to predict the error?

  There hides certain high negative realtionship between these two factors.However, we have transaction data for the whole year of 2016 only. It is lack of strong evidence to prove that the transaction frequency of 2017 stays low in the last season as 2016 did. Therefore, the transaction value might be one important factor to predict the logerror, but the error might not be predicted based solely on the transaction trends.

# 1.4  Find more important feature to influence the logerror 

  Beside the possible importance of transaction data for the logerror, according to Zillow, the accuracy of Zestimate depands on the available data supplied by the homeowners. prop16 and prop17 contain those value from the property owners. So, let's combine respective properties and the trainning data by parcelid. The output files will tell us the physical features value and their logerros of the sold property in 2016 and 2017. As well as, the hidden relationships among those factors and logerror might be disclosure.

# 1.4.1 Join property data and train data

```{r}
mergeid16 <- merge(x=train16_beforeOct, y=prop16, by = "parcelid", all.x = TRUE)
mergeid16B <- merge(x=train16_afterOct, y=prop16, by = "parcelid", all.x = TRUE)
mergeid17 <- merge(x=train17, y=prop17, by = "parcelid", all.x = TRUE)
```

After the files are merged, let's clean the non-numeric data, as the later correlation is calculated with numberic value only.

```{r}
mergeid16 <- select_if(mergeid16,is.numeric) 
mergeid17 <- select_if(mergeid17,is.numeric) 
```

# 1.4.2 check the missing data for each field

```{r,fig.width=10, fig.height=20}
#sum(!is.na(mergeid16n$airconditioningtypeid)) # count the row number of column with values
#airc16 <- ddply(mergeid16n, .(airconditioningtypeid), "nrow") # count row number for each unique value in the column

temp16M <- data.frame(colSums(!is.na(mergeid16)))
names(temp16M)[1] <- c("values")

ggplot(temp16M,aes(x=reorder(rownames(temp16M),-values), y=values)) + geom_bar( fill = "pink", stat = "identity") + xlab("Property Physical Features (2016)") + ylab("Available values Counts for Featrues")+ scale_y_continuous(limits = c(0, 91000), breaks = seq(0, 91000, 5000)) +coord_flip() + theme_bw()

```

  As we can see, from the top to feature of "unicnt" where appears obsious decline of the data volume, there are 29 (near 50%) property features that were supplied leass values. Let us narrow down the size of the dataset and focus on figuring out the relationship between the logerror and the feature variables with nearly full values.

```{r}
subset(temp16M,rownames(temp16M)=="unitcnt") #52628 
```
```{r}
temp16M1 <- subset(temp16M,temp16M > 52628)
nrow(temp16M1)
```
  There are 27 features that contain nealy full values in 2016.

  The same operation is applied to deal with the missing data of 2017.
```{r,fig.width=10, fig.height=20}

temp17M <- data.frame(colSums(!is.na(mergeid17)))
names(temp17M)[1] <- c("values")

ggplot(temp17M,aes(x=reorder(rownames(temp17M),-values), y=values)) + geom_bar( fill = "pink", stat = "identity") + xlab("Property Physical Features (2017)") + ylab("Available values Counts for Featrues")+ scale_y_continuous(limits = c(0, 91000), breaks = seq(0, 91000, 5000)) +coord_flip() + theme_bw()
```

```{r}
subset(temp17M,rownames(temp17M)=="unitcnt") #50703
```

```{r}
temp17M1 <- subset(temp17M,temp17M > 50703)
nrow(temp17M1)
```
  The same as 2016, there are 27 numeric features that contain nealy full values in 2017.
  
# 1.4.3 Narrow down the datasize and focus on discovering the valuable factors that might influence the logerror
  
  Let's create two data frameworks with those 27 valuable features for 2016 and 2017.
  
```{r} 
# based on the 27 feature names of temp16M1
temp16df <- select(mergeid16, parcelid, logerror,transactiondate, month, bathroomcnt, bedroomcnt, calculatedbathnbr, calculatedfinishedsquarefeet, finishedsquarefeet12, fips,fullbathcnt, latitude, longitude, lotsizesquarefeet, propertylandusetypeid, rawcensustractandblock, regionidcity, regionidcounty, regionidzip, roomcnt, yearbuilt,structuretaxvaluedollarcnt,taxvaluedollarcnt, assessmentyear, landtaxvaluedollarcnt, taxamount, censustractandblock)

# based on the 27 feature names of temp16M1
temp17df <- select(mergeid17, parcelid, logerror,transactiondate, month, bathroomcnt, bedroomcnt, calculatedbathnbr, calculatedfinishedsquarefeet, finishedsquarefeet12, fips,fullbathcnt, latitude, longitude, lotsizesquarefeet, propertylandusetypeid, rawcensustractandblock, regionidcity, regionidcounty, regionidzip, roomcnt, yearbuilt,structuretaxvaluedollarcnt,taxvaluedollarcnt, assessmentyear, landtaxvaluedollarcnt, taxamount, censustractandblock)
``` 


  With reference to the forum information supplied from Andrew Martin (Data Scientist at Zillow), https://www.kaggle.com/c/zillow-prize-1/discussion/34168, there are some duplicate data for the features of the properties. 
  bathroomcnt = calculatedbathnbr = fullbathcnt: calculatedbathnbr and fullbathcnt are calculated by the assessor. bathroomcnt is calculated by Zillow.
  calculatedfinishedsquarefeet = finishedsquarefeet12: finishedsquaredfeet12 is calculated by Zillow. Calculatedfinishedsquarefeet is calculated by the assessor.
  taxvaluedollarcnt = landtaxvaluedollarcnt + structuretaxvaluedollarcnt
  As the fips is named based on the individual county, so does the regionidcounty. Let's see if they are duplicated.
  
```{r}
ddply(temp16df, .(fips), "nrow")
ddply(temp16df, .(regionidcounty), "nrow") 
```

  The results show that the properties from a same palce have the same fips code and regionidecounty.
  fips = "6037", regionidcounty = "3101", Los Angeles County
  fips = "6059", regionidcounty = "1286", Orange County
  fips = "6111", regionidcounty = "2061", Ventura County

  In sum, there are 6 features contain the duplicated value for the parcelid. It needs to be cleaned.
  
# Clean Duplicated data

```{r} 
temp16df <- select(mergeid16, parcelid, logerror,transactiondate, month, bathroomcnt, bedroomcnt, calculatedfinishedsquarefeet, fips,latitude, longitude, lotsizesquarefeet, propertylandusetypeid, rawcensustractandblock, regionidcity, regionidzip, roomcnt, yearbuilt, assessmentyear, taxvaluedollarcnt, taxamount, censustractandblock)

temp17df <- select(mergeid17, parcelid, logerror,transactiondate, month, bathroomcnt, bedroomcnt, calculatedfinishedsquarefeet, fips,latitude, longitude, lotsizesquarefeet, propertylandusetypeid, rawcensustractandblock, regionidcity, regionidzip, roomcnt, yearbuilt, assessmentyear, landtaxvaluedollarcnt, taxamount, censustractandblock)
```  

# Replace the missing data with 0 to make all the value of feature full filled
```{r}
temp16df <- replace(temp16df, is.na(temp16df), 0)
temp17df <- replace(temp17df, is.na(temp17df), 0)
```

# Explore the correlation among each dataframe

```{r,fig.width=10, fig.height=7}
cor16 <- cor(temp16df) 
corrplot(cor16, method="circle") 
```


```{r,fig.width=10, fig.height=7}
cor17 <- cor(temp17df) 
corrplot(cor17, method="circle") 
```



  There is something wrong with the assessmentyear when calculating the correlation for 2016. Let's see what value is in this column.

```{r}
ddply(temp16df, .(assessmentyear), "nrow")
ddply(temp17df, .(assessmentyear), "nrow")
```
  It seems all the parcelid listed in train16 were assessed in 2015 and all the parcelid listed in train17 were assessed in 2016. The constant value results in the error messeage of the calculation. Meanwhile, there is no future transactiondate. Therefore, we can delete the column of assessment year, transactiondate and the month for further prediction.
  
  In conclusion, we cannot find any correlation of logerror and other features as the above two correlation matrices, even through those features are filled fully. Those value might have directly relationship with the price prediction of the parcelid. 
  (Note: I have tried different ways like using "caret" and "randomForest" to find out the relationship between logerror and the combination of 21 features. The model seems does not fit these datasets. The operations caused computer dead often. As the suggestion from my supervisor, the part can be skipped.)
  
  So far, we have finished the prepration phase and most of the data analysis. Let's proceed the prediction model based on the helpful values we found so far.
  
# Part 2: Prediction Model

  As we need to forecast the actual logerror value for the last quarter of 2016 and 2017, multiple linear regression model might contribute more helpful function than the binary prediction models like decision tree and logic regression.
  
  Although we cannot find the correlation between the features and logerror, we need to try first those 21 features for prediction before ignoring using them to build the prediction formula. Let's built two models with using 21 features and transactiondate seperately to explore their MSE value. If 

# 2.1 Model with using 21 features Vs. Model with using transactiondata only

```{r}
set.seed(100)
test16_a <- sample(1:nrow(temp16df), 0.7*nrow(temp16df))
train16_a<- temp16df[test16_a,]
test16_a <- temp16df[-test16_a,]

model16_a = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = train16_a)
summary(model16_a)
pre16_a <- data.frame(predict(model16_a, test16_a)) 
mse(pre16_a,test16_a$logerror)

```

```{r}
model16_b = lm(logerror ~ transactiondate, data = train16_a)
pre16_b <- data.frame(predict(model16_b, test16_a)) 
mse(pre16_b,test16_a$logerror)

```
  
  The MSE value returned from two different prediction models almost equal(21-feature 0.0252 vs. transactiondate 0.0253). It means that applying the model16_a into the logerror prediction for total 3millions parcelid in 2017 is workable.

  Furthermore, as our target is to predict the logerror month by month in the last quarter of the year, what we are supposed to do next is to find out what size of the training data can achieve better predction score. For example, use one month data as training data to predict the next month data. Or use three month data to predict the next month data. Or use the existing data to predict the next month data. As there is no strong evidence to prove the logerror trend of 2016 represent the one of 2017 with the existing data. Thus, we need to calculate the average prediction score for the different prediction data sizes. Then, find out the most propriate sizes to apply in the prediction of year 2017.

# 2.1.1 Predict month data based on previous one month data 
# Prepare the different sizes of training data and testing data

```{r}
mergeid16B <- replace(mergeid16B, is.na(mergeid16B), 0)
mergeid16BP <- select(mergeid16B, parcelid, logerror, transactiondate,month, bathroomcnt, bedroomcnt, calculatedfinishedsquarefeet, fips,latitude, longitude, lotsizesquarefeet, propertylandusetypeid, rawcensustractandblock, regionidcity, regionidzip, roomcnt, yearbuilt, assessmentyear, taxvaluedollarcnt, taxamount, censustractandblock)
jan16 <- subset(temp16df, month == "1")
feb16 <- subset(temp16df, month == "2")
mar16 <- subset(temp16df, month == "3")
apr16 <- subset(temp16df, month == "4")
may16 <- subset(temp16df, month == "5")
jun16 <- subset(temp16df, month == "6")
jul16 <- subset(temp16df, month == "7")
aug16 <- subset(temp16df, month == "8")
sep16 <- subset(temp16df, month == "9")
oct16 <- subset(mergeid16BP, month == "10")
nov16 <- subset(mergeid16BP, month=="11")
dec16 <- subset(mergeid16BP, month =="12")
```

Jan data predicts Feb data
```{r}
model16_jan = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jan16)
pre16_feb <- data.frame(predict(model16_jan, feb16)) 
mse(pre16_feb,feb16$logerror)
```


Feb data predicts Mar data
```{r}
model16_feb = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = feb16)
pre16_mar <- data.frame(predict(model16_feb, mar16)) 
mse(pre16_mar,mar16$logerror)

```
Mar data predicts Apr data
```{r}
model16_mar = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = mar16)
pre16_apr <- data.frame(predict(model16_mar, apr16)) 
mse(pre16_apr,apr16$logerror)

```
Apr data predicts May data
```{r}
model16_apr = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = apr16)
pre16_may <- data.frame(predict(model16_apr, may16)) 
mse(pre16_may,may16$logerror)

```

May data predicts June data
```{r}
model16_may = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = may16)
pre16_jun <- data.frame(predict(model16_may, jun16)) 
mse(pre16_jun,jun16$logerror)

```
June data predicts July data
```{r}
model16_jun = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jun16)
pre16_jul <- data.frame(predict(model16_jun, jul16)) 
mse(pre16_jul,jul16$logerror)

```
July data predicts Aug data
```{r}
model16_jul = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jul16)
pre16_aug <- data.frame(predict(model16_jul, aug16)) 
mse(pre16_aug,aug16$logerror)
```
Aug data predicts Sep data
```{r}
model16_aug = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = aug16)
pre16_sep <- data.frame(predict(model16_aug, sep16)) 
mse(pre16_sep,sep16$logerror)
```
Sep data predicts Oct data
```{r}
model16_sep = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = sep16)
pre16_oct <- data.frame(predict(model16_sep, oct16)) 
mse(pre16_oct,oct16$logerror)
```
Oct data predicts Nov data
```{r}
model16_oct = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = oct16)
pre16_nov <- data.frame(predict(model16_oct, nov16)) 
mse(pre16_nov,nov16$logerror)
```
Nov data predicts Dec data
```{r}
model16_nov = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = nov16)
pre16_dec <- data.frame(predict(model16_nov, dec16)) 
mse(pre16_dec,dec16$logerror)
```


# 2.1.2 Predict month data based on previous three month data 
# Prepare the different sizes of training data and testing data

```{r}
jfm16 <- rbind(jan16,feb16,mar16)
fma16 <- rbind(feb16,mar16,apr16)
mam16 <- rbind(mar16,apr16,may16)
amj16 <- rbind(apr16,may16,jun16)
mjj16 <- rbind(may16,jun16,jul16)
jja16 <- rbind(jun16,jul16,aug16)
jas16 <- rbind(jul16,aug16,sep16)
aso16 <- rbind(aug16,sep16,oct16)
son16 <- rbind(sep16,oct16,nov16)
```

Jan+Feb+Mar data predicts Apr data
```{r}
model16_jfm = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jfm16)
pre16_apr2 <- data.frame(predict(model16_jfm, apr16)) 
mse(pre16_apr2,apr16$logerror)
```

Feb+Mar+Apr data predicts May data
```{r}
model16_fma = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = fma16)
pre16_may2 <- data.frame(predict(model16_fma, may16)) 
mse(pre16_may2,may16$logerror)
```

Mar+Apr+May data predicts June data
```{r}
model16_mam = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = mam16)
pre16_jun2 <- data.frame(predict(model16_mam, jun16)) 
mse(pre16_jun2,jun16$logerror)
```

Apr+May+June data predicts July data
```{r}
model16_amj = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = amj16)
pre16_jul2 <- data.frame(predict(model16_amj, jul16)) 
mse(pre16_jul2,jul16$logerror)
```

May+June+July data predicts Aug data
```{r}
model16_mjj = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = mjj16)
pre16_aug2 <- data.frame(predict(model16_mjj, aug16)) 
mse(pre16_aug2,aug16$logerror)
```

June+July+Aug data predicts Sep data
```{r}
model16_jja = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jja16)
pre16_sep2 <- data.frame(predict(model16_jja, sep16)) 
mse(pre16_sep2,sep16$logerror)
```

July+Aug+Sep data predicts Oct data
```{r}
model16_jas = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jas16)
pre16_oct2 <- data.frame(predict(model16_jas, oct16)) 
mse(pre16_oct2,oct16$logerror)
```

Aug+Sep+Oct data predicts Nov data
```{r}
model16_aso = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = aso16)
pre16_nov2 <- data.frame(predict(model16_aso, nov16)) 
mse(pre16_nov2,nov16$logerror)
```

Sep+Oct+Nov data predicts Dec data
```{r}
model16_son = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = son16)
pre16_dec2 <- data.frame(predict(model16_son, dec16)) 
mse(pre16_dec2,dec16$logerror)
```

# 2.1.3 Predict month data based on all previous data 

Prepare the different sizes of training data and testing data
```{r}
jtos16 <- rbind(jan16,feb16,mar16,apr16,may16,jun16,jul16,aug16,sep16)
jtoo16 <- rbind(jan16,feb16,mar16,apr16,may16,jun16,jul16,aug16,sep16, oct16)
jton16 <- rbind(jan16,feb16,mar16,apr16,may16,jun16,jul16,aug16,sep16, oct16, nov16)
```

Predict Oct data
```{r}
model16_jtos = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jtos16)
pre16_oct3 <- data.frame(predict(model16_jtos, oct16)) 
mse(pre16_oct2,oct16$logerror)
```

Predict Nov data
```{r}
model16_jtoo = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jtoo16)
pre16_nov3 <- data.frame(predict(model16_jtoo, nov16)) 
mse(pre16_nov3,nov16$logerror)
```
Predict Dec data
```{r}
model16_jton = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = jton16)
pre16_dec3 <- data.frame(predict(model16_jton, dec16)) 
mse(pre16_dec3,dec16$logerror)
```

All the MSE values are made into a table. Pls see the attached table "Zillow Prediction Data Sizes_MSE".
To sum up, the training data size with 3months data got the best MSE score to predict the data.
Predict month data based on previous one month data, Average MSE: 0.027734
Predict month data based on previous three month data, Average MSE: 0.02455
Pedict month data based on all previous data, Average MSE: 0.024566

# 2.2 Applying the model and the way to select the training dataset into the prediction of 2017

```{r}
mergeid17 <- replace(mergeid17, is.na(mergeid17), 0)
prop17 <- replace(prop17, is.na(prop17),0)
pre17 <- select(mergeid17, parcelid,logerror, transactiondate,month, bathroomcnt,bedroomcnt,calculatedfinishedsquarefeet,fips,latitude, longitude,lotsizesquarefeet,propertylandusetypeid,rawcensustractandblock,regionidcity,regionidzip,roomcnt,yearbuilt, taxvaluedollarcnt,taxamount,censustractandblock)

traindata17 <- subset(pre17, pre17$month > 6) # use the data of July, Aug and Sept to be training data
model17_jas = lm(logerror ~ bathroomcnt+bedroomcnt+calculatedfinishedsquarefeet+fips+latitude+ longitude+lotsizesquarefeet+propertylandusetypeid+rawcensustractandblock+regionidcity+regionidzip+roomcnt+yearbuilt+ taxvaluedollarcnt+taxamount+ censustractandblock, data = traindata17)
pre17_oct <- data.frame(predict(model17_jas, prop17))# predict logerror for 3millions parcelid
nrow(pre17_oct)
head(pre17_oct)

```
As the mean of logerror of 2017 from Jan to Setp is 0.01675494 that means the overestimatioin is nearly 1.7%. To predict 3millions of parcelid in Nov and Dec, I will use the following ways to reduce the gap between the future actual logerror.
```{r}
pre17_nov <- pre17_oct[1] * (1-1.7/100)
pre17_dec <- pre17_nov[1] * (1-1.7/100)
head(pre17_nov)
head(pre17_dec)

```



  
# Part 3: Other data analysis

# The most popular bathrooms (2 bathrooms, then 3 and 1)
```{r}
bath <-data.frame(ddply(temp16df, .(bathroomcnt), "nrow"))
bath <- arrange(bath, desc(nrow))
head(bath)

ggplot(bath) + geom_bar(aes(x= bathroomcnt, y=nrow), fill = "pink", stat = "identity") + xlab("Bath Room Number") + ylab("Frequency")+ scale_y_continuous(limits = c(0, 37000), breaks = seq(0, 37000, 1000)) + scale_x_continuous(limits = c(-0.5, 12), breaks = seq(-0.5, 12, 0.5)) + theme_bw()

```


# The most popular bedrooms (3 bedrooms then 2 and 4)
```{r}

bed <-data.frame(ddply(temp16df, .(bedroomcnt), "nrow"))
bed <- arrange(bed, desc(nrow))
head(bed)

ggplot(bed) + geom_bar(aes(x= bedroomcnt, y=nrow), fill = "pink", stat = "identity") + xlab("Bed Room Number") + ylab("Frequency")+ scale_y_continuous(limits = c(0, 36000), breaks = seq(0, 36000, 1000)) + scale_x_continuous(limits = c(-1, 15), breaks = seq(-1, 15, 1)) + theme_bw()

```


# The most popular property type id (261 - Single Family Residential then 266 - Condominium) 
```{r}
pt <-data.frame(ddply(temp16df, .(propertylandusetypeid), "nrow"))
pt <- arrange(pt, desc(nrow))
head(pt)
```

# The most popular county (6037 - LA, then 6059 - OR, last 6111 - VE)
```{r}

fips <-data.frame(ddply(temp16df, .(fips), "nrow"))
fips <- arrange(fips, desc(nrow))
head(fips)

```


# The most popular room (0 room - maybe the value is not supplied, then with 6 rooms and 7 rooms)
```{r}

room <-data.frame(ddply(temp16df, .(roomcnt), "nrow"))
room <- arrange(room, desc(nrow))
head(room)

```


# The most popular taxvaluedollarcnt (between 300k and 500k)

```{r}

tax <-data.frame(ddply(mergeid16, .(taxvaluedollarcnt), "nrow"))
tax <- arrange(tax, desc(nrow), desc(taxvaluedollarcnt))
tax[which.max(tax$taxvaluedollarcnt),]
tax[which.min(tax$taxvaluedollarcnt),]
head(tax)

```

# The most popular squarefeet (around 1200sq.feet=112sq.meter)

```{r}
feet <-data.frame(ddply(mergeid16, .(calculatedfinishedsquarefeet), "nrow"))
feet <- arrange(feet, desc(nrow))
feet[which.max(feet$calculatedfinishedsquarefeet),]
feet[which.min(feet$calculatedfinishedsquarefeet),]
head(feet)
plot(feet)
```

# The most popular parcelid is built in 1955 (top 30: 1950 - 1989, wider range (1950 - 2007))
```{r}

year <-data.frame(ddply(mergeid16, .(yearbuilt), "nrow"))
year <- arrange(year, desc(nrow))

head(year)

ggplot(year) + geom_bar(aes(x= yearbuilt, y=nrow), fill = "pink", stat = "identity") + xlab("Year Built") + ylab("Frequency")+ scale_y_continuous(limits = c(0, 2000), breaks = seq(0, 2000, 100)) +scale_x_continuous(limits = c(1880, 2020), breaks = seq(0, 2020, 10)) + theme_bw()

```



# Explore the parcelid (out: total sold: 90275, unique parcel id: 90150)
#(there are 125 parcelid were sold more than 2 times)
```{r}

id <-data.frame(ddply(mergeid16, .(parcelid), "nrow"))
id <- arrange(id, desc(nrow))

head(id)
plot(id)

```











